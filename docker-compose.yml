services:
  llm:
    image: szemil99/llm-app:latest
    container_name: llm-api
    ports: ['8000:8000']
    env_file:
      - .env
    volumes:
      - models:/models # named volume, łatwe sprzątanie per projekt (-p)
    gpus: all
    restart: unless-stopped

volumes:
  models: {}
